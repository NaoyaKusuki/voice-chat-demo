<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>Realtime Full-Duplex Voice Chat</title>
  <style>
    body { font-family: sans-serif; margin: 20px; text-align: center; }
    h1 { font-size: 20px; margin-bottom: 10px; }

    button {
      margin: 10px;
      padding: 12px 24px;
      font-size: 16px;
      border: none;
      border-radius: 6px;
      cursor: pointer;
      transition: background-color 0.3s ease, transform 0.1s ease;
    }
    button:hover { transform: scale(1.05); }

    #startButton { background-color: #0072BC; color: white; }

    #micButton {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 10px;
      color: white;
      background-color: #0072BC;
    }

    #micIndicator {
      width: 14px;
      height: 14px;
      border-radius: 50%;
      background-color: #ccc;
      transition: background-color 0.3s ease, opacity 0.3s ease;
    }

    #micIndicator.on {
      background-color: #ff3b3b;
      animation: blink 1s infinite;
    }

    @keyframes blink {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.3; }
    }

    #micIndicator.off {
      background-color: #777;
      opacity: 0.8;
      animation: none;
    }
  </style>
</head>

<body>
  <!-- ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ -->
  <script>
    const correctPassword = "0033";
    const input = prompt("ã“ã®ãƒ‡ãƒ¢ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§ä¿è­·ã•ã‚Œã¦ã„ã¾ã™ã€‚4æ¡ã®æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š");
    if (input !== correctPassword) {
      document.body.innerHTML = "<h2>ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚</h2><p>æ­£ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚</p>";
      throw new Error("Access denied");
    }
  </script>

  <h1>Full-Duplex Voice Chat Demo_OpenAI RealtimeAPIï¼ˆUIã‚·ãƒ³ãƒ—ãƒ«ver.ï¼‰</h1>
  <p style="color: red; font-weight: bold; margin-top: -5px;">
  â€»APIæ–™é‡‘ãŒã‹ã‹ã‚‹ãŸã‚ã€åˆ©ç”¨å¾Œã¯å¿…ãšã“ã®ãƒšãƒ¼ã‚¸ã‚’é–‰ã˜ã¦ãã ã•ã„ã€‚
  </p>
  <button id="startButton">Start Chat</button>
  <button id="micButton" class="on">
    <div id="micIndicator" class="on"></div>
    <span id="micLabel">ãƒã‚¤ã‚¯ON</span>
  </button>

  <script>
    // -----------------------
    // å¤‰æ•°ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ï¼‰
    // -----------------------
    let pc;
    let localStream;
    let micEnabled = true;
    let dataChannel;

    // -----------------------
    // ç›¸æ§Œé–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆèª¿æ•´å¯ï¼‰
    // -----------------------
    const BACKCHANNEL_MIN_INTERVAL_MS = 900; // ç›¸æ§Œã®æœ€ä½é–“éš”
    const BACKCHANNEL_SPEAKING_MS = 600;     // ç™ºè©±ç¶™ç¶šãŒã“ã‚Œä»¥ä¸Šãªã‚‰ç›¸æ§Œå¯¾è±¡
    const VOLUME_THRESHOLD = 0.02;           // RMSé–¾å€¤ï¼ˆè¦èª¿æ•´ï¼‰

    let lastBackchannelAt = 0;
    let speakingStart = null;
    let lastModelResponseAt = 0; // ãƒ¢ãƒ‡ãƒ«/ã‚µãƒ¼ãƒã®ç›´è¿‘å¿œç­”ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—

    // -----------------------
    // startChat - ãƒ¡ã‚¤ãƒ³å‡¦ç†
    // -----------------------
    async function startChat() {
      const res = await fetch("/api/session");
      const data = await res.json();
      const EPHEMERAL_KEY = data.client_secret.value;

      pc = new RTCPeerConnection();

      // ãƒªãƒ¢ãƒ¼ãƒˆéŸ³å£°ã‚’å†ç”Ÿã™ã‚‹ <audio>
      const audioEl = document.createElement("audio");
      audioEl.autoplay = true;
      document.body.appendChild(audioEl);
      pc.ontrack = (event) => { audioEl.srcObject = event.streams[0]; };

      // ãƒã‚¤ã‚¯å–å¾—
      localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      localStream.getTracks().forEach(track => pc.addTrack(track, localStream));

      // ===== VAD ç”¨ã® AudioContext / analyser ã‚’ä½œã‚‹ï¼ˆlocalStream ãŒå¿…è¦ï¼‰ =====
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioCtx.createMediaStreamSource(localStream);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048; // è§£åƒåº¦ï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯èƒ½ï¼‰
      source.connect(analyser);
      // ======================================================================

      // DataChannel ã‚’ä½œæˆï¼ˆoai-events ã‚’ä½¿ç”¨ï¼‰
      dataChannel = pc.createDataChannel("oai-events");

      // DataChannel ã®å—ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆç›£è¦–ï¼ˆãƒ¢ãƒ‡ãƒ«ã®å¿œç­”æ¤œå‡ºç”¨ï¼‰
      attachDataChannelListeners(dataChannel);

      dataChannel.onopen = () => {
        console.log("âœ… DataChannel opened");

        // åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ—¢å­˜ã®æŒ¨æ‹¶ï¼‰
        dataChannel.send(JSON.stringify({
          type: "response.create",
          response: {
            modalities: ["audio", "text"],
            instructions: "ã“ã‚“ã«ã¡ã¯ï¼éŸ³å£°ã§ãŠè©±ã—ã—ã¾ã—ã‚‡ã†ã€‚",
          },
        }));

        alert("âœ… AIã¨ã®éŸ³å£°ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã—ã¾ã—ãŸï¼");

        // ã“ã“ã§ VAD ã‚’é–‹å§‹ã—ã¦ç›¸æ§Œãƒˆãƒªã‚¬ã‚’æœ‰åŠ¹ã«ã™ã‚‹
        startBackchannelVAD(analyser, dataChannel);
      };

      // Offer ä½œæˆã€œ Realtime API ã« SDP é€ä¿¡
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      const baseUrl = "https://api.openai.com/v1/realtime";
      const model = "gpt-4o-realtime-preview-2024-12-17";

      const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${EPHEMERAL_KEY}`,
          "Content-Type": "application/sdp"
        },
        body: offer.sdp
      });

      const answer = { type: "answer", sdp: await sdpResponse.text() };
      await pc.setRemoteDescription(answer);
    }

    // -----------------------
    // ãƒã‚¤ã‚¯ã® ON/OFF åˆ‡æ›¿
    // -----------------------
    function toggleMic() {
      if (!localStream) return;

      micEnabled = !micEnabled;
      localStream.getAudioTracks().forEach(track => {
        track.enabled = micEnabled;
      });

      const micIndicator = document.getElementById("micIndicator");
      const micLabel = document.getElementById("micLabel");

      if (micEnabled) {
        micLabel.textContent = "ãƒã‚¤ã‚¯ON";
        micIndicator.className = "on";
      } else {
        micLabel.textContent = "ãƒã‚¤ã‚¯OFF";
        micIndicator.className = "off";
      }
    }

    // -----------------------
    // VAD ï¼‹ ç›¸æ§Œãƒˆãƒªã‚¬ï¼ˆanalyser ã¨ dataChannel ã‚’æ¸¡ã™ï¼‰
    // -----------------------
    function startBackchannelVAD(analyser, dataChannel) {
      const data = new Uint8Array(analyser.fftSize);

      function frame() {
        analyser.getByteTimeDomainData(data);
        let sum = 0;
        for (let i = 0; i < data.length; i++) {
          const v = (data[i] - 128) / 128;
          sum += v * v;
        }
        const rms = Math.sqrt(sum / data.length);

        const now = Date.now();

        if (rms > VOLUME_THRESHOLD) {
          if (!speakingStart) speakingStart = now;
          const spokeFor = now - speakingStart;

          // ç™ºè©±ãŒç¶™ç¶šã—ã¦ã„ã¦ã€æœ€å°é–“éš”ã‚’æº€ãŸã—ã€ã‹ã¤ãƒ¢ãƒ‡ãƒ«ç›´è¿‘å¿œç­”ã¨è¢«ã‚‰ãªã„å ´åˆã«é€ä¿¡
          if (
            spokeFor > BACKCHANNEL_SPEAKING_MS &&
            (now - lastBackchannelAt > BACKCHANNEL_MIN_INTERVAL_MS) &&
            (now - lastModelResponseAt > 1000)
          ) {
            sendBackchannelResponseCreate(dataChannel);
            lastBackchannelAt = now;
          }
        } else {
          speakingStart = null;
        }

        requestAnimationFrame(frame);
      }

      frame();
    }

    // -----------------------
    // DataChannel çµŒç”±ã§ response.create ã‚’æŠ•ã’ã‚‹ï¼ˆç›¸æ§Œå°‚ç”¨ï¼‰
    // -----------------------
    function sendBackchannelResponseCreate(dataChannel) {
      if (!dataChannel || dataChannel.readyState !== "open") return;

      const now = Date.now();
      if (now - lastBackchannelAt < BACKCHANNEL_MIN_INTERVAL_MS) return;

      const payload = {
        type: "response.create",
        response: {
          modalities: ["audio"],
          instructions: "ç›¸æ§Œã ã‘ã‚’çŸ­ãä¸€èªã§è¿”ã—ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§ã€‚å€™è£œ: ã¯ã„, ãˆãˆ, ãªã‚‹ã»ã©, ãã†ã§ã™ã­ã€‚çŸ­ãæŠ‘åˆ¶çš„ã«ã€‚",
          // voice: "verse" // å¿…è¦ãªã‚‰è¿½åŠ 
        }
      };

      dataChannel.send(JSON.stringify(payload));
    }

    // -----------------------
    // DataChannel ã®å—ä¿¡ã‚’ç›£è¦–ã—ã¦ãƒ¢ãƒ‡ãƒ«å¿œç­”ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ›´æ–°
    // -----------------------
    function attachDataChannelListeners(dc) {
      if (!dc) return;

      dc.onmessage = (evt) => {
        try {
          const msg = JSON.parse(evt.data || "{}");

          // Realtime ã®ã‚¤ãƒ™ãƒ³ãƒˆã§ model ã®ç”Ÿæˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆãŒæ¥ãŸã‚‰ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ›´æ–°
          // å®Ÿéš›ã®ã‚¤ãƒ™ãƒ³ãƒˆåã¯ç’°å¢ƒã«ã‚ˆã‚Šç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ãŒã€response.* ç³»ã‚’æƒ³å®š
          if (typeof msg.type === "string" && msg.type.startsWith("response.")) {
            lastModelResponseAt = Date.now();
          }
          // console.debug("DC message:", msg);
        } catch (e) {
          // éJSONãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ç„¡è¦–
        }
      };

      dc.onclose = () => {
        console.log("DataChannel closed");
      };
      dc.onerror = (e) => {
        console.warn("DataChannel error", e);
      };
    }

    // -----------------------
    // ã‚¤ãƒ™ãƒ³ãƒˆãƒã‚¤ãƒ³ãƒ‰
    // -----------------------
    document.getElementById("startButton").addEventListener("click", startChat);
    document.getElementById("micButton").addEventListener("click", toggleMic);
  </script>
</body>
</html>
